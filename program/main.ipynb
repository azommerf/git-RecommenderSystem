{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    print(\"\\njupyter cell run successfully\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "import sys # For input/output to terminal\n",
    "import os # For saving filepath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests # For requesting and downloading data set from URL\n",
    "import gzip # For unzipping the data set\n",
    "import pandas as pd # For handling dataframe\n",
    "import numpy as np # For sparse grid\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix # Sparse matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to prepare the following Amazon data set (can take a while if not downloaded): amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz? [y]/[n]  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azomm\\Google Drive\\Unil\\FS19\\Programming\\git-final\\program\\data\\amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\n",
      "\n",
      "Checking if data is downloaded.\n",
      "\n",
      "File already exists. Continue with creating data frame.\n",
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "#  Prepare the data set from Amazon\n",
    "# Choose category here: https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt\n",
    "\n",
    "\n",
    "# INSERT URL HERE\n",
    "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\"\n",
    "# url = \"http://ctdbase.org/reports/CTD_genes_pathways.tsv.gz\" # This is just an example data base which is smaller to handle\n",
    "\n",
    "filename = url.split('/')[-1]\n",
    "workingdir = os.path.abspath('')\n",
    "datadir = \"data\" # Directory where data is stored\n",
    "filepath_tsvgz = os.path.join(workingdir, datadir, filename)\n",
    "filepath_tsv = filepath_tsvgz[0:-3]\n",
    "\n",
    "\n",
    "while True:\n",
    "    download_request = input(\"\\nDo you want to prepare the following Amazon data set (can take a while if not downloaded): {}? [y]/[n] \".format(filename))\n",
    "    print(filepath_tsvgz)\n",
    "\n",
    "\n",
    "    if download_request == \"y\":\n",
    "\n",
    "        def download_gz(url, filepath_tsvgz, filename):\n",
    "\n",
    "            filepath_tsv = filepath_tsvgz[0:-3]\n",
    "\n",
    "            # Check if data file already exists\n",
    "            exists_tsvgz = os.path.isfile(filepath_tsvgz)\n",
    "            if exists_tsvgz: print(\"\\nFile already downloaded and compressed.\")\n",
    "            else:\n",
    "                print(\"\\nFile does not exist. Continue with download process.\")\n",
    "\n",
    "                print(\"\\n{:^50}\".format(\"...downloading the data...\"))\n",
    "\n",
    "                # Retrieve data from URL\n",
    "                r = requests.get(url, stream=True)\n",
    "                total_length = r.headers.get('content-length')\n",
    "\n",
    "                with open(filepath_tsvgz, 'wb') as f:\n",
    "                    # Show download progress bar\n",
    "                    if total_length is None:\n",
    "                        f.write(r.content)\n",
    "                    else:\n",
    "                        downloaded = 0\n",
    "                        total_length = int(total_length)\n",
    "                        for data in r.iter_content(chunk_size=max(int(total_length/1000), 1024*1024)):\n",
    "                            downloaded += len(data)\n",
    "                            f.write(data)\n",
    "                            done = int(50*downloaded/total_length)\n",
    "                            sys.stdout.write('\\r[{}{}]'.format('█' * done, '.' * (50-done)))\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "                print(\"Downloaded \"+filename+\" successfully.\")\n",
    "\n",
    "            # Unzip file  \n",
    "            print(\"\\n\\nunzipping the file...\")\n",
    "            zipped = gzip.GzipFile(filepath_tsvgz, 'rb')\n",
    "            zipped_content = zipped.read()\n",
    "            zipped.close()\n",
    "            unzipped = open(filepath_tsv, 'wb')\n",
    "            unzipped.write(zipped_content)\n",
    "            unzipped.close()\n",
    "            print(\"\\nFile decompressed successfully.\")\n",
    "\n",
    "            # Delete zipped file\n",
    "            os.remove(filepath_tsvgz) # delete compressed data\n",
    "            print(\"Compressed file deleted successfully.\")\n",
    "            print(\"File saved in the following location:\\n{}\".format(filepath_tsv))\n",
    "\n",
    "        exists_tsv = os.path.isfile(filepath_tsv)\n",
    "        # Execute download\n",
    "        if not exists_tsv:\n",
    "            download_gz(url, filepath_tsvgz, filename)\n",
    "            break\n",
    "        else: \n",
    "            print(\"\\nFile already exists. Continue with creating data frame. \")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(\"\\nChecking if data is downloaded.\")\n",
    "\n",
    "        # Check if decompressed data file already exists\n",
    "        exists = os.path.isfile(filepath_tsv)\n",
    "        if exists:\n",
    "            print(\"\\nFile already exists. Continue with creating data frame.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\nData file not found. Download the file to continue program.\")\n",
    "            \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...creating dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 5782: expected 15 fields, saw 22\\nSkipping line 31979: expected 15 fields, saw 22\\nSkipping line 32408: expected 15 fields, saw 22\\nSkipping line 45709: expected 15 fields, saw 22\\nSkipping line 64585: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 115742: expected 15 fields, saw 22\\nSkipping line 125537: expected 15 fields, saw 22\\nSkipping line 127580: expected 15 fields, saw 22\\nSkipping line 128696: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 143851: expected 15 fields, saw 22\\nSkipping line 147069: expected 15 fields, saw 22\\nSkipping line 149233: expected 15 fields, saw 22\\nSkipping line 167536: expected 15 fields, saw 22\\nSkipping line 168535: expected 15 fields, saw 22\\nSkipping line 171659: expected 15 fields, saw 22\\nSkipping line 184533: expected 15 fields, saw 22\\nSkipping line 184624: expected 15 fields, saw 22\\nSkipping line 184908: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 219150: expected 15 fields, saw 22\\nSkipping line 223178: expected 15 fields, saw 22\\nSkipping line 234333: expected 15 fields, saw 22\\nSkipping line 256242: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 268157: expected 15 fields, saw 22\\nSkipping line 276191: expected 15 fields, saw 22\\nSkipping line 277091: expected 15 fields, saw 22\\nSkipping line 288516: expected 15 fields, saw 22\\nSkipping line 289901: expected 15 fields, saw 22\\nSkipping line 292922: expected 15 fields, saw 22\\nSkipping line 308964: expected 15 fields, saw 22\\nSkipping line 325233: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 354051: expected 15 fields, saw 22\\nSkipping line 360552: expected 15 fields, saw 22\\nSkipping line 362489: expected 15 fields, saw 22\\nSkipping line 383798: expected 15 fields, saw 22\\nSkipping line 392390: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 456105: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Create dataframe\n",
    "\n",
    "\n",
    "\n",
    "# Create pandas dataframe\n",
    "print()\n",
    "print(\"\\n...creating dataframe...\")\n",
    "df = pd.read_csv(filepath_tsv, delimiter='\\t', encoding=\"utf-8\", error_bad_lines=False)\n",
    "\n",
    "# Write dataframe to excel\n",
    "# df = df.applymap(lambda x: x.encode('unicode_escape').\n",
    "#              decode('utf-8') if isinstance(x, str) else x)\n",
    "# df.to_excel(\"data.xlsx\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
      "0          US     45610553   RMDCHWD0Y5OZ9  B00HH62VB6       618218723   \n",
      "1          US     14640079   RZSL0BALIYUNU  B003LRN53I       986692292   \n",
      "2          US      6111003   RIZR67JKUDBI0  B0006VMBHI       603261968   \n",
      "3          US      1546619  R27HL570VNL85F  B002B55TRG       575084461   \n",
      "4          US     12222213  R34EBU9QDWJ1GD  B00N1YPXW2       165236328   \n",
      "5          US     46018513  R1WCUI4Z1SIQEO  B001N4GRGS       134151483   \n",
      "6          US     10225065   RL5LNO26GAVJ1  B009PJRMHQ       694166585   \n",
      "7          US      6356995  R3GYQ5W8JHP8SB  B00NKBDAZS       446431775   \n",
      "8          US     35297198  R30SHYQXGG5EYC  B006MIU7U2       125871705   \n",
      "9          US     32139520  R14YLXA56NP51I  B000FIBD0I       771888534   \n",
      "\n",
      "                                       product_title     product_category  \\\n",
      "0  AGPtek® 10 Isolated Output 9V 12V 18V Guitar P...  Musical Instruments   \n",
      "1         Sennheiser HD203 Closed-Back DJ Headphones  Musical Instruments   \n",
      "2                   AudioQuest LP record clean brush  Musical Instruments   \n",
      "3      Hohner Inc. 560BX-BF Special Twenty Harmonica  Musical Instruments   \n",
      "4        Blue Yeti USB Microphone - Blackout Edition  Musical Instruments   \n",
      "5                  Middle Atlantic Products QFAN-119  Musical Instruments   \n",
      "6  Kmise 1pc Pickguard for Gibson Sg Standard 3-p...  Musical Instruments   \n",
      "7  Kealoha Concert Ukulele - Stunning NEW Printed...  Musical Instruments   \n",
      "8  Halco 80000 - MR16/3WW/FL/LED2 MR16 Flood LED ...  Musical Instruments   \n",
      "9  Gator GPTBLACK Plywood Pedal Board with Black ...  Musical Instruments   \n",
      "\n",
      "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
      "0            3              0            1    N                 N   \n",
      "1            5              0            0    N                 Y   \n",
      "2            3              0            1    N                 Y   \n",
      "3            5              0            0    N                 Y   \n",
      "4            5              0            0    N                 Y   \n",
      "5            5              0            0    N                 N   \n",
      "6            2              3            4    N                 Y   \n",
      "7            5              0            0    N                 Y   \n",
      "8            5              0            0    N                 Y   \n",
      "9            5              1            1    N                 N   \n",
      "\n",
      "                                     review_headline  \\\n",
      "0                                        Three Stars   \n",
      "1                                         Five Stars   \n",
      "2                                        Three Stars   \n",
      "3  I purchase these for a friend in return for pl...   \n",
      "4                                         Five Stars   \n",
      "5                                         Five Stars   \n",
      "6  Will not Fit Epiphone SG Special or any other ...   \n",
      "7                                         Five Stars   \n",
      "8  Works fine. Hope it lasts through the warranty...   \n",
      "9  I upgraded the power cord to a heavier gauge w...   \n",
      "\n",
      "                                         review_body review_date  \n",
      "0        Works very good, but induces ALOT of noise.  2015-08-31  \n",
      "1             Nice headphones at a reasonable price.  2015-08-31  \n",
      "2                       removes dust. does not clean  2015-08-31  \n",
      "3  I purchase these for a friend in return for pl...  2015-08-31  \n",
      "4                            This is an awesome mic!  2015-08-31  \n",
      "5  Used to cool equipment inside credenzas.  Work...  2015-08-31  \n",
      "6  Note- Does not Fit Epiphone SG Special! Mine i...  2015-08-31  \n",
      "7          Well built Ukulele! My daughter loves it!  2015-08-31  \n",
      "8  Had to replace a new light after a lightning s...  2015-08-31  \n",
      "9  I've owned multiple fixed boards over the year...  2015-08-31  \n"
     ]
    }
   ],
   "source": [
    "print(df[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique products: 123284\n",
      "Number of unique customers: 572785\n",
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# Nearest neighbors method\n",
    "# (1) Create sparse matrix with unique customer and unique item index and the corresponding star rating\n",
    "#    needed data: start_rating, product_id, customer_id\n",
    "# (2) Compute nearest neighbors\n",
    "\n",
    "# Calculate total number of products and customers (for range calculation)\n",
    "prodNo = len(set(df[\"product_id\"])) # Number of products\n",
    "custNo = len(set(df[\"customer_id\"])) # Number of customers\n",
    "print(\"Number of unique products: {}\".format(prodNo))\n",
    "print(\"Number of unique customers: {}\".format(custNo))\n",
    "\n",
    "# Get unique product and customer IDs and index them\n",
    "prodUnique_indexed = dict(zip(np.unique(df[\"product_id\"]), list(range(prodNo))))\n",
    "custUnique_indexed = dict(zip(np.unique(df[\"customer_id\"]), list(range(custNo))))\n",
    "prodUnique_reverseIndexed = dict(zip(list(range(prodNo)), np.unique(df[\"product_id\"])))\n",
    "custUnique_reverseIndexed = dict(zip(list(range(custNo)), np.unique(df[\"customer_id\"])))\n",
    "\n",
    "# Finally go through each row of dataframe and assign index \n",
    "custIndex = [custUnique_indexed[i] for i in df[\"customer_id\"]]\n",
    "prodIndex = [prodUnique_indexed[i] for i in df[\"product_id\"]]\n",
    "\n",
    "# Create indexed matrix\n",
    "data1 = pd.DataFrame(custIndex, columns=[\"custIndex\"])\n",
    "data2 = pd.DataFrame(prodIndex, columns=[\"prodIndex\"])\n",
    "df_indexed = pd.DataFrame(df[\"star_rating\"], columns=[\"star_rating\"])\n",
    "df_indexed.insert(0, \"prodIndex\", data2)\n",
    "df_indexed.insert(0, \"custIndex\", data1)\n",
    "\n",
    "\n",
    "# Create the sparse matrix\n",
    "\n",
    "#df_pivot = df_indexed.pivot(index=\"prodIndex\", columns=\"custIndex\", values=\"star_rating\").fillna(0)\n",
    "#df_sparse = csr_matrix(df_rating.values)\n",
    "X = csr_matrix((df_indexed[\"star_rating\"], (prodIndex, custIndex)), shape=(prodNo, custNo))\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        custIndex  prodIndex  star_rating\n",
      "0          479499     105233            3\n",
      "1          160876      50301            5\n",
      "2           57327      12350            3\n",
      "3           17443      40258            5\n",
      "4          117460     115112            5\n",
      "5          484538      34676            5\n",
      "6           83050      85882            2\n",
      "7           58876     115945            5\n",
      "8          372973      72736            5\n",
      "9          346753      18267            5\n",
      "10         379440       4483            5\n",
      "11          52170     119645            4\n",
      "12         392909      28707            3\n",
      "13         358758      85162            2\n",
      "14         253627       5113            5\n",
      "15         568052     110643            5\n",
      "16          46165      99229            5\n",
      "17         151281     107058            1\n",
      "18         306485     100864            5\n",
      "19         193738     123133            5\n",
      "20         305934      83815            5\n",
      "21         515740      94429            5\n",
      "22           1355     106267            4\n",
      "23          84064      57144            5\n",
      "24         376143      47798            5\n",
      "25         510188      59820            5\n",
      "26         179746     105781            5\n",
      "27         137482      39439            5\n",
      "28         173900     121948            5\n",
      "29         273909      94207            5\n",
      "...           ...        ...          ...\n",
      "903974     559147        140            5\n",
      "903975     516854        159            4\n",
      "903976     520855        138            2\n",
      "903977     523530        143            5\n",
      "903978     516142        163            4\n",
      "903979     522887        163            4\n",
      "903980     570937        141            3\n",
      "903981     516642        138            5\n",
      "903982     517680        141            4\n",
      "903983     541938        141            1\n",
      "903984     554525        145            4\n",
      "903985     520855        138            2\n",
      "903986     520855        139            4\n",
      "903987     540403        145            5\n",
      "903988     520350        145            1\n",
      "903989     521992        145            5\n",
      "903990     520375        157            5\n",
      "903991     520745        157            5\n",
      "903992     521227        142            4\n",
      "903993     552764        144            5\n",
      "903994     572783        144            4\n",
      "903995     537559         41            4\n",
      "903996     537322         91            5\n",
      "903997     529382        139            5\n",
      "903998     533127        141            4\n",
      "903999     549463        138            4\n",
      "904000     556404        146            5\n",
      "904001     535989        146            4\n",
      "904002     534864        141            4\n",
      "904003     534864        146            5\n",
      "\n",
      "[904004 rows x 3 columns]\n",
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "#df_indexed.fillna(0)\n",
    "#df_pivot = df_indexed.pivot(index=\"prodIndex\", columns=\"custIndex\", values=\"star_rating\")\n",
    "\n",
    "print(df_indexed)\n",
    "#print(df_indexed)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a6 approach\n",
    "\n",
    "rating = len(set(df[\"star_rating\"]))\n",
    "prodNum = len(set(df[\"product_id\"]))\n",
    "custNum = len(set(df[\"customer_id\"]))\n",
    "df[\"customer_id\"] = df[\"customer_id\"].astype(str)\n",
    "\n",
    "def create_X(df,custNum,prodNum):\n",
    "    cust_mapper = dict(zip(np.unique(df[\"customer_id\"]), list(range(n))))\n",
    "    prod_mapper = dict(zip(np.unique(df[\"product_id\"]), list(range(d))))\n",
    "\n",
    "    cust_inverse_mapper = dict(zip(list(range(n)), np.unique(df[\"customer_id\"])))\n",
    "    prod_inverse_mapper = dict(zip(list(range(d)), np.unique(df[\"product_id\"])))\n",
    "\n",
    "    cust_ind = [user_mapper[i] for i in df[user_key]]\n",
    "    prod_ind = [item_mapper[i] for i in df[item_key]]\n",
    "\n",
    "    X = sparse_matrix((df[\"rating\"], (\"customer_id\", \"product_id\")), shape=(custNum,prodNum))\n",
    "    \n",
    "    return X, cust_mapper, prod_mapper, cust_inverse_mapper, prod_inverse_mapper, cust_ind, prod_ind\n",
    "\n",
    "X, cust_mapper, prod_mapper, cust_inverse_mapper, prod_inverse_mapper, cust_ind, prod_ind = create_X(rating, custNum, prodNum)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
