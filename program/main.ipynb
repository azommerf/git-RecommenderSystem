{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    print(\"\\njupyter cell run successfully\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "import sys # For input/output to terminal\n",
    "import os # For saving filepath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests # For requesting and downloading data set from URL\n",
    "import gzip # For unzipping the data set\n",
    "import pandas as pd # For handling dataframe\n",
    "import numpy as np # For sparse grid\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix as sparse_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to prepare the following Amazon data set (can take a while if not downloaded): amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz? [y]/[n]  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azomm\\Google Drive\\Unil\\FS19\\Programming\\git-final\\program\\data\\amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\n",
      "\n",
      "File already exists. Continue with creating data frame. \n",
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "#  Prepare the data set from Amazon\n",
    "# Choose category here: https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt\n",
    "\n",
    "\n",
    "# INSERT URL HERE\n",
    "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\"\n",
    "# url = \"http://ctdbase.org/reports/CTD_genes_pathways.tsv.gz\" # This is just an example data base which is smaller to handle\n",
    "\n",
    "filename = url.split('/')[-1]\n",
    "workingdir = os.path.abspath('')\n",
    "datadir = \"data\" # Directory where data is stored\n",
    "filepath_tsvgz = os.path.join(workingdir, datadir, filename)\n",
    "filepath_tsv = filepath_tsvgz[0:-3]\n",
    "\n",
    "\n",
    "while True:\n",
    "    download_request = input(\"\\nDo you want to prepare the following Amazon data set (can take a while if not downloaded): {}? [y]/[n] \".format(filename))\n",
    "    print(filepath_tsvgz)\n",
    "\n",
    "\n",
    "    if download_request == \"y\":\n",
    "\n",
    "        def download_gz(url, filepath_tsvgz, filename):\n",
    "\n",
    "            filepath_tsv = filepath_tsvgz[0:-3]\n",
    "\n",
    "            # Check if data file already exists\n",
    "            exists_tsvgz = os.path.isfile(filepath_tsvgz)\n",
    "            if exists_tsvgz: print(\"\\nFile already downloaded and compressed.\")\n",
    "            else:\n",
    "                print(\"\\nFile does not exist. Continue with download process.\")\n",
    "\n",
    "                print(\"\\n{:^50}\".format(\"...downloading the data...\"))\n",
    "\n",
    "                # Retrieve data from URL\n",
    "                r = requests.get(url, stream=True)\n",
    "                total_length = r.headers.get('content-length')\n",
    "\n",
    "                with open(filepath_tsvgz, 'wb') as f:\n",
    "                    # Show download progress bar\n",
    "                    if total_length is None:\n",
    "                        f.write(r.content)\n",
    "                    else:\n",
    "                        downloaded = 0\n",
    "                        total_length = int(total_length)\n",
    "                        for data in r.iter_content(chunk_size=max(int(total_length/1000), 1024*1024)):\n",
    "                            downloaded += len(data)\n",
    "                            f.write(data)\n",
    "                            done = int(50*downloaded/total_length)\n",
    "                            sys.stdout.write('\\r[{}{}]'.format('â–ˆ' * done, '.' * (50-done)))\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "                print(\"Downloaded \"+filename+\" successfully.\")\n",
    "\n",
    "            # Unzip file  \n",
    "            print(\"\\n\\nunzipping the file...\")\n",
    "            zipped = gzip.GzipFile(filepath_tsvgz, 'rb')\n",
    "            zipped_content = zipped.read()\n",
    "            zipped.close()\n",
    "            unzipped = open(filepath_tsv, 'wb')\n",
    "            unzipped.write(zipped_content)\n",
    "            unzipped.close()\n",
    "            print(\"\\nFile decompressed successfully.\")\n",
    "\n",
    "            # Delete zipped file\n",
    "            os.remove(filepath_tsvgz) # delete compressed data\n",
    "            print(\"Compressed file deleted successfully.\")\n",
    "            print(\"File saved in the following location:\\n{}\".format(filepath_tsv))\n",
    "\n",
    "        exists_tsv = os.path.isfile(filepath_tsv)\n",
    "        # Execute download\n",
    "        if not exists_tsv:\n",
    "            download_gz(url, filepath_tsvgz, filename)\n",
    "            break\n",
    "        else: \n",
    "            print(\"\\nFile already exists. Continue with creating data frame. \")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(\"\\nChecking if data is downloaded.\")\n",
    "\n",
    "        # Check if decompressed data file already exists\n",
    "        exists = os.path.isfile(filepath_tsv)\n",
    "        if exists:\n",
    "            print(\"\\nFile already exists. Continue with creating data frame.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\nData file not found. Download the file to continue program.\")\n",
    "            \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...creating dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 5782: expected 15 fields, saw 22\\nSkipping line 31979: expected 15 fields, saw 22\\nSkipping line 32408: expected 15 fields, saw 22\\nSkipping line 45709: expected 15 fields, saw 22\\nSkipping line 64585: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 115742: expected 15 fields, saw 22\\nSkipping line 125537: expected 15 fields, saw 22\\nSkipping line 127580: expected 15 fields, saw 22\\nSkipping line 128696: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 143851: expected 15 fields, saw 22\\nSkipping line 147069: expected 15 fields, saw 22\\nSkipping line 149233: expected 15 fields, saw 22\\nSkipping line 167536: expected 15 fields, saw 22\\nSkipping line 168535: expected 15 fields, saw 22\\nSkipping line 171659: expected 15 fields, saw 22\\nSkipping line 184533: expected 15 fields, saw 22\\nSkipping line 184624: expected 15 fields, saw 22\\nSkipping line 184908: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 219150: expected 15 fields, saw 22\\nSkipping line 223178: expected 15 fields, saw 22\\nSkipping line 234333: expected 15 fields, saw 22\\nSkipping line 256242: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 268157: expected 15 fields, saw 22\\nSkipping line 276191: expected 15 fields, saw 22\\nSkipping line 277091: expected 15 fields, saw 22\\nSkipping line 288516: expected 15 fields, saw 22\\nSkipping line 289901: expected 15 fields, saw 22\\nSkipping line 292922: expected 15 fields, saw 22\\nSkipping line 308964: expected 15 fields, saw 22\\nSkipping line 325233: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 354051: expected 15 fields, saw 22\\nSkipping line 360552: expected 15 fields, saw 22\\nSkipping line 362489: expected 15 fields, saw 22\\nSkipping line 383798: expected 15 fields, saw 22\\nSkipping line 392390: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 456105: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Create dataframe\n",
    "\n",
    "\n",
    "\n",
    "# Create pandas dataframe\n",
    "print()\n",
    "print(\"\\n...creating dataframe...\")\n",
    "df = pd.read_csv(filepath_tsv, delimiter='\\t', encoding=\"utf-8\", error_bad_lines=False)\n",
    "\n",
    "# Write dataframe to excel\n",
    "# df = df.applymap(lambda x: x.encode('unicode_escape').\n",
    "#              decode('utf-8') if isinstance(x, str) else x)\n",
    "# df.to_excel(\"data.xlsx\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
      "0          US     45610553   RMDCHWD0Y5OZ9  B00HH62VB6       618218723   \n",
      "1          US     14640079   RZSL0BALIYUNU  B003LRN53I       986692292   \n",
      "2          US      6111003   RIZR67JKUDBI0  B0006VMBHI       603261968   \n",
      "3          US      1546619  R27HL570VNL85F  B002B55TRG       575084461   \n",
      "4          US     12222213  R34EBU9QDWJ1GD  B00N1YPXW2       165236328   \n",
      "5          US     46018513  R1WCUI4Z1SIQEO  B001N4GRGS       134151483   \n",
      "6          US     10225065   RL5LNO26GAVJ1  B009PJRMHQ       694166585   \n",
      "7          US      6356995  R3GYQ5W8JHP8SB  B00NKBDAZS       446431775   \n",
      "8          US     35297198  R30SHYQXGG5EYC  B006MIU7U2       125871705   \n",
      "9          US     32139520  R14YLXA56NP51I  B000FIBD0I       771888534   \n",
      "\n",
      "                                       product_title     product_category  \\\n",
      "0  AGPtekÂ® 10 Isolated Output 9V 12V 18V Guitar P...  Musical Instruments   \n",
      "1         Sennheiser HD203 Closed-Back DJ Headphones  Musical Instruments   \n",
      "2                   AudioQuest LP record clean brush  Musical Instruments   \n",
      "3      Hohner Inc. 560BX-BF Special Twenty Harmonica  Musical Instruments   \n",
      "4        Blue Yeti USB Microphone - Blackout Edition  Musical Instruments   \n",
      "5                  Middle Atlantic Products QFAN-119  Musical Instruments   \n",
      "6  Kmise 1pc Pickguard for Gibson Sg Standard 3-p...  Musical Instruments   \n",
      "7  Kealoha Concert Ukulele - Stunning NEW Printed...  Musical Instruments   \n",
      "8  Halco 80000 - MR16/3WW/FL/LED2 MR16 Flood LED ...  Musical Instruments   \n",
      "9  Gator GPTBLACK Plywood Pedal Board with Black ...  Musical Instruments   \n",
      "\n",
      "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
      "0            3              0            1    N                 N   \n",
      "1            5              0            0    N                 Y   \n",
      "2            3              0            1    N                 Y   \n",
      "3            5              0            0    N                 Y   \n",
      "4            5              0            0    N                 Y   \n",
      "5            5              0            0    N                 N   \n",
      "6            2              3            4    N                 Y   \n",
      "7            5              0            0    N                 Y   \n",
      "8            5              0            0    N                 Y   \n",
      "9            5              1            1    N                 N   \n",
      "\n",
      "                                     review_headline  \\\n",
      "0                                        Three Stars   \n",
      "1                                         Five Stars   \n",
      "2                                        Three Stars   \n",
      "3  I purchase these for a friend in return for pl...   \n",
      "4                                         Five Stars   \n",
      "5                                         Five Stars   \n",
      "6  Will not Fit Epiphone SG Special or any other ...   \n",
      "7                                         Five Stars   \n",
      "8  Works fine. Hope it lasts through the warranty...   \n",
      "9  I upgraded the power cord to a heavier gauge w...   \n",
      "\n",
      "                                         review_body review_date  \n",
      "0        Works very good, but induces ALOT of noise.  2015-08-31  \n",
      "1             Nice headphones at a reasonable price.  2015-08-31  \n",
      "2                       removes dust. does not clean  2015-08-31  \n",
      "3  I purchase these for a friend in return for pl...  2015-08-31  \n",
      "4                            This is an awesome mic!  2015-08-31  \n",
      "5  Used to cool equipment inside credenzas.  Work...  2015-08-31  \n",
      "6  Note- Does not Fit Epiphone SG Special! Mine i...  2015-08-31  \n",
      "7          Well built Ukulele! My daughter loves it!  2015-08-31  \n",
      "8  Had to replace a new light after a lightning s...  2015-08-31  \n",
      "9  I've owned multiple fixed boards over the year...  2015-08-31  \n"
     ]
    }
   ],
   "source": [
    "print(df[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2cd7471ce044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprod_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust_inverse_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprod_inverse_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprod_ind\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprod_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust_inverse_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprod_inverse_mapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcust_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprod_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustNum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprodNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2cd7471ce044>\u001b[0m in \u001b[0;36mcreate_X\u001b[1;34m(df, custNum, prodNum)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustNum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprodNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mcust_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"customer_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprod_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"product_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# Nearest neighbors method\n",
    "# (1) Create sparse matrix with unique customer and unique item index and the corresponding star rating\n",
    "#    needed data: start_rating, product_id, customer_id\n",
    "# (2) Compute nearest neighbors\n",
    "\n",
    "\n",
    "rating = len(set(df[\"star_rating\"]))\n",
    "prodNum = len(set(df[\"product_id\"]))\n",
    "custNum = len(set(df[\"customer_id\"]))\n",
    "\n",
    "def create_X(df,custNum,prodNum):\n",
    "    cust_mapper = dict(zip(np.unique(df[\"customer_id\"]), list(range(n))))\n",
    "    prod_mapper = dict(zip(np.unique(df[\"product_id\"]), list(range(d))))\n",
    "\n",
    "    cust_inverse_mapper = dict(zip(list(range(n)), np.unique(df[\"customer_id\"])))\n",
    "    prod_inverse_mapper = dict(zip(list(range(d)), np.unique(df[\"product_id\"])))\n",
    "\n",
    "    cust_ind = [user_mapper[i] for i in df[user_key]]\n",
    "    prod_ind = [item_mapper[i] for i in df[item_key]]\n",
    "\n",
    "    X = sparse_matrix((df[\"rating\"], (\"customer_id\", \"product_id\")), shape=(custNum,prodNum))\n",
    "    \n",
    "    return X, cust_mapper, prod_mapper, cust_inverse_mapper, prod_inverse_mapper, cust_ind, prod_ind\n",
    "\n",
    "X, cust_mapper, prod_mapper, cust_inverse_mapper, prod_inverse_mapper, cust_ind, prod_ind = create_X(rating, custNum, prodNum)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
