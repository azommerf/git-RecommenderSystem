{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully. 2019-05-09 09:43:44.818708\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "def test():\n",
    "    print(\"\\njupyter cell run successfully. {}\".format(now))\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully. 2019-05-09 09:43:44.818708\n"
     ]
    }
   ],
   "source": [
    "import sys # For input/output to terminal\n",
    "import os # For saving filepath\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests # For requesting and downloading data set from URL\n",
    "import gzip # For unzipping the data set\n",
    "import pandas as pd # For handling dataframe\n",
    "import numpy as np # For sparse grid\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix # Sparse matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to prepare the following Amazon data set (can take a while if not downloaded): amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz? [y]/[n]  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azomm\\Google Drive\\Unil\\FS19\\Programming\\git-final\\program\\data\\amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\n",
      "\n",
      "Checking if data is downloaded.\n",
      "\n",
      "File already exists. Continue with creating data frame.\n",
      "\n",
      "jupyter cell run successfully. 2019-05-09 09:43:44.818708\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "#  Prepare the data set from Amazon\n",
    "# Choose category here: https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt\n",
    "\n",
    "\n",
    "# INSERT URL HERE\n",
    "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\"\n",
    "# url = \"http://ctdbase.org/reports/CTD_genes_pathways.tsv.gz\" # This is just an example data base which is smaller to handle\n",
    "\n",
    "filename = url.split('/')[-1]\n",
    "workingdir = os.path.abspath('')\n",
    "datadir = \"data\" # Directory where data is stored\n",
    "filepath_tsvgz = os.path.join(workingdir, datadir, filename)\n",
    "filepath_tsv = filepath_tsvgz[0:-3]\n",
    "\n",
    "\n",
    "while True:\n",
    "    download_request = input(\"\\nDo you want to prepare the following Amazon data set (can take a while if not downloaded): {}? [y]/[n] \".format(filename))\n",
    "    print(filepath_tsvgz)\n",
    "\n",
    "\n",
    "    if download_request == \"y\":\n",
    "\n",
    "        def download_gz(url, filepath_tsvgz, filename):\n",
    "\n",
    "            filepath_tsv = filepath_tsvgz[0:-3]\n",
    "\n",
    "            # Check if data file already exists\n",
    "            exists_tsvgz = os.path.isfile(filepath_tsvgz)\n",
    "            if exists_tsvgz: print(\"\\nFile already downloaded and compressed.\")\n",
    "            else:\n",
    "                print(\"\\nFile does not exist. Continue with download process.\")\n",
    "\n",
    "                print(\"\\n{:^50}\".format(\"...downloading the data...\"))\n",
    "\n",
    "                # Retrieve data from URL\n",
    "                r = requests.get(url, stream=True)\n",
    "                total_length = r.headers.get('content-length')\n",
    "\n",
    "                with open(filepath_tsvgz, 'wb') as f:\n",
    "                    # Show download progress bar\n",
    "                    if total_length is None:\n",
    "                        f.write(r.content)\n",
    "                    else:\n",
    "                        downloaded = 0\n",
    "                        total_length = int(total_length)\n",
    "                        for data in r.iter_content(chunk_size=max(int(total_length/1000), 1024*1024)):\n",
    "                            downloaded += len(data)\n",
    "                            f.write(data)\n",
    "                            done = int(50*downloaded/total_length)\n",
    "                            sys.stdout.write('\\r[{}{}]'.format('â–ˆ' * done, '.' * (50-done)))\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "                print(\"Downloaded \"+filename+\" successfully.\")\n",
    "\n",
    "            # Unzip file  \n",
    "            print(\"\\n\\nunzipping the file...\")\n",
    "            zipped = gzip.GzipFile(filepath_tsvgz, 'rb')\n",
    "            zipped_content = zipped.read()\n",
    "            zipped.close()\n",
    "            unzipped = open(filepath_tsv, 'wb')\n",
    "            unzipped.write(zipped_content)\n",
    "            unzipped.close()\n",
    "            print(\"\\nFile decompressed successfully.\")\n",
    "\n",
    "            # Delete zipped file\n",
    "            os.remove(filepath_tsvgz) # delete compressed data\n",
    "            print(\"Compressed file deleted successfully.\")\n",
    "            print(\"File saved in the following location:\\n{}\".format(filepath_tsv))\n",
    "\n",
    "        exists_tsv = os.path.isfile(filepath_tsv)\n",
    "        # Execute download\n",
    "        if not exists_tsv:\n",
    "            download_gz(url, filepath_tsvgz, filename)\n",
    "            break\n",
    "        else: \n",
    "            print(\"\\nFile already exists. Continue with creating data frame. \")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(\"\\nChecking if data is downloaded.\")\n",
    "\n",
    "        # Check if decompressed data file already exists\n",
    "        exists = os.path.isfile(filepath_tsv)\n",
    "        if exists:\n",
    "            print(\"\\nFile already exists. Continue with creating data frame.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\nData file not found. Download the file to continue program.\")\n",
    "            \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...creating dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 5782: expected 15 fields, saw 22\\nSkipping line 31979: expected 15 fields, saw 22\\nSkipping line 32408: expected 15 fields, saw 22\\nSkipping line 45709: expected 15 fields, saw 22\\nSkipping line 64585: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 115742: expected 15 fields, saw 22\\nSkipping line 125537: expected 15 fields, saw 22\\nSkipping line 127580: expected 15 fields, saw 22\\nSkipping line 128696: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 143851: expected 15 fields, saw 22\\nSkipping line 147069: expected 15 fields, saw 22\\nSkipping line 149233: expected 15 fields, saw 22\\nSkipping line 167536: expected 15 fields, saw 22\\nSkipping line 168535: expected 15 fields, saw 22\\nSkipping line 171659: expected 15 fields, saw 22\\nSkipping line 184533: expected 15 fields, saw 22\\nSkipping line 184624: expected 15 fields, saw 22\\nSkipping line 184908: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 219150: expected 15 fields, saw 22\\nSkipping line 223178: expected 15 fields, saw 22\\nSkipping line 234333: expected 15 fields, saw 22\\nSkipping line 256242: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 268157: expected 15 fields, saw 22\\nSkipping line 276191: expected 15 fields, saw 22\\nSkipping line 277091: expected 15 fields, saw 22\\nSkipping line 288516: expected 15 fields, saw 22\\nSkipping line 289901: expected 15 fields, saw 22\\nSkipping line 292922: expected 15 fields, saw 22\\nSkipping line 308964: expected 15 fields, saw 22\\nSkipping line 325233: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 354051: expected 15 fields, saw 22\\nSkipping line 360552: expected 15 fields, saw 22\\nSkipping line 362489: expected 15 fields, saw 22\\nSkipping line 383798: expected 15 fields, saw 22\\nSkipping line 392390: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 456105: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jupyter cell run successfully. 2019-05-09 09:43:44.818708\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Create dataframe\n",
    "\n",
    "\n",
    "\n",
    "# Create pandas dataframe\n",
    "print()\n",
    "print(\"\\n...creating dataframe...\")\n",
    "df = pd.read_csv(filepath_tsv, delimiter='\\t', encoding=\"utf-8\", error_bad_lines=False)\n",
    "\n",
    "# Write dataframe to excel\n",
    "# df = df.applymap(lambda x: x.encode('unicode_escape').\n",
    "#              decode('utf-8') if isinstance(x, str) else x)\n",
    "# df.to_excel(\"data.xlsx\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>45610553</td>\n",
       "      <td>RMDCHWD0Y5OZ9</td>\n",
       "      <td>B00HH62VB6</td>\n",
       "      <td>618218723</td>\n",
       "      <td>AGPtekÂ® 10 Isolated Output 9V 12V 18V Guitar P...</td>\n",
       "      <td>Musical Instruments</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>Works very good, but induces ALOT of noise.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>14640079</td>\n",
       "      <td>RZSL0BALIYUNU</td>\n",
       "      <td>B003LRN53I</td>\n",
       "      <td>986692292</td>\n",
       "      <td>Sennheiser HD203 Closed-Back DJ Headphones</td>\n",
       "      <td>Musical Instruments</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Nice headphones at a reasonable price.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>6111003</td>\n",
       "      <td>RIZR67JKUDBI0</td>\n",
       "      <td>B0006VMBHI</td>\n",
       "      <td>603261968</td>\n",
       "      <td>AudioQuest LP record clean brush</td>\n",
       "      <td>Musical Instruments</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>removes dust. does not clean</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>1546619</td>\n",
       "      <td>R27HL570VNL85F</td>\n",
       "      <td>B002B55TRG</td>\n",
       "      <td>575084461</td>\n",
       "      <td>Hohner Inc. 560BX-BF Special Twenty Harmonica</td>\n",
       "      <td>Musical Instruments</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I purchase these for a friend in return for pl...</td>\n",
       "      <td>I purchase these for a friend in return for pl...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>12222213</td>\n",
       "      <td>R34EBU9QDWJ1GD</td>\n",
       "      <td>B00N1YPXW2</td>\n",
       "      <td>165236328</td>\n",
       "      <td>Blue Yeti USB Microphone - Blackout Edition</td>\n",
       "      <td>Musical Instruments</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>This is an awesome mic!</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     45610553   RMDCHWD0Y5OZ9  B00HH62VB6       618218723   \n",
       "1          US     14640079   RZSL0BALIYUNU  B003LRN53I       986692292   \n",
       "2          US      6111003   RIZR67JKUDBI0  B0006VMBHI       603261968   \n",
       "3          US      1546619  R27HL570VNL85F  B002B55TRG       575084461   \n",
       "4          US     12222213  R34EBU9QDWJ1GD  B00N1YPXW2       165236328   \n",
       "\n",
       "                                       product_title     product_category  \\\n",
       "0  AGPtekÂ® 10 Isolated Output 9V 12V 18V Guitar P...  Musical Instruments   \n",
       "1         Sennheiser HD203 Closed-Back DJ Headphones  Musical Instruments   \n",
       "2                   AudioQuest LP record clean brush  Musical Instruments   \n",
       "3      Hohner Inc. 560BX-BF Special Twenty Harmonica  Musical Instruments   \n",
       "4        Blue Yeti USB Microphone - Blackout Edition  Musical Instruments   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            3              0            1    N                 N   \n",
       "1            5              0            0    N                 Y   \n",
       "2            3              0            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                        Three Stars   \n",
       "1                                         Five Stars   \n",
       "2                                        Three Stars   \n",
       "3  I purchase these for a friend in return for pl...   \n",
       "4                                         Five Stars   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0        Works very good, but induces ALOT of noise.  2015-08-31  \n",
       "1             Nice headphones at a reasonable price.  2015-08-31  \n",
       "2                       removes dust. does not clean  2015-08-31  \n",
       "3  I purchase these for a friend in return for pl...  2015-08-31  \n",
       "4                            This is an awesome mic!  2015-08-31  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique products: 123284\n",
      "Number of unique customers: 572785\n",
      "\n",
      "jupyter cell run successfully. 2019-05-09 09:43:44.818708\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# Nearest neighbors method\n",
    "# (1) Create sparse matrix with unique customer and unique item index and the corresponding star rating\n",
    "#    needed data: start_rating, product_id, customer_id\n",
    "# (2) Compute nearest neighbors\n",
    "\n",
    "# Calculate total number of products and customers (for range calculation)\n",
    "prodNo = len(set(df[\"product_id\"])) # Number of products\n",
    "custNo = len(set(df[\"customer_id\"])) # Number of customers\n",
    "print(\"Number of unique products: {}\".format(prodNo))\n",
    "print(\"Number of unique customers: {}\".format(custNo))\n",
    "\n",
    "# Get unique product and customer IDs and index them\n",
    "prodUnique_indexed = dict(zip(np.unique(df[\"product_id\"]), list(range(prodNo))))\n",
    "custUnique_indexed = dict(zip(np.unique(df[\"customer_id\"]), list(range(custNo))))\n",
    "prodUnique_reverseIndexed = dict(zip(list(range(prodNo)), np.unique(df[\"product_id\"])))\n",
    "custUnique_reverseIndexed = dict(zip(list(range(custNo)), np.unique(df[\"customer_id\"])))\n",
    "\n",
    "# Finally go through each row of dataframe and assign index \n",
    "custIndex = [custUnique_indexed[i] for i in df[\"customer_id\"]]\n",
    "prodIndex = [prodUnique_indexed[i] for i in df[\"product_id\"]]\n",
    "\n",
    "# Create indexed matrix\n",
    "df_custIndex = pd.DataFrame(custIndex, columns=[\"custIndex\"])\n",
    "df_prodIndex = pd.DataFrame(prodIndex, columns=[\"prodIndex\"])\n",
    "df_indexed = pd.DataFrame(df[\"star_rating\"], columns=[\"star_rating\"])\n",
    "df_indexed.insert(0, \"prodIndex\", df_prodIndex)\n",
    "df_indexed.insert(0, \"custIndex\", df_custIndex)\n",
    "\n",
    "\n",
    "# Create the sparse matrix based on a matrix with dimensions \n",
    "# (no. of unique products x no. of unique customres)\n",
    "# Description from official scipy documentation:\n",
    "# csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
    "# where data, row_ind and col_ind satisfy the relationship a[row_ind[k], col_ind[k]] = data[k].\n",
    "X = csr_matrix((df_indexed[\"star_rating\"], (prodIndex, custIndex)), shape=(prodNo, custNo))\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   custIndex\n",
      "0     479499\n",
      "1     160876\n",
      "2      57327\n",
      "3      17443\n",
      "4     117460\n",
      "   prodIndex\n",
      "0     105233\n",
      "1      50301\n",
      "2      12350\n",
      "3      40258\n",
      "4     115112\n",
      "   custIndex  prodIndex  star_rating\n",
      "0     479499     105233            3\n",
      "1     160876      50301            5\n",
      "2      57327      12350            3\n",
      "3      17443      40258            5\n",
      "4     117460     115112            5\n",
      "904004\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index contains duplicate entries, cannot reshape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-df1788e80aaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#df_features = df_indexed.pivot(index='prodIndex', columns='custIndex', values='star_rating')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_indexed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'prodIndex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'custIndex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'star_rating'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   5192\u001b[0m         \"\"\"\n\u001b[0;32m   5193\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5194\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5196\u001b[0m     _shared_docs['pivot_table'] = \"\"\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m    413\u001b[0m             indexed = self._constructor_sliced(self[values].values,\n\u001b[0;32m    414\u001b[0m                                                index=index)\n\u001b[1;32m--> 415\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   2897\u001b[0m         \"\"\"\n\u001b[0;32m   2898\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    499\u001b[0m         unstacker = _Unstacker(obj.values, obj.index, level=level,\n\u001b[0;32m    500\u001b[0m                                \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m                                constructor=obj._constructor_expanddim)\n\u001b[0m\u001b[0;32m    502\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munstacker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, index, level, value_columns, fill_value, constructor)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_sorted_values_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_sorted_values_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             raise ValueError('Index contains duplicate entries, '\n\u001b[0m\u001b[0;32m    176\u001b[0m                              'cannot reshape')\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Index contains duplicate entries, cannot reshape"
     ]
    }
   ],
   "source": [
    "print(df_custIndex.head())\n",
    "print(df_prodIndex.head())\n",
    "print(df_indexed.head())\n",
    "print(len(df_indexed))\n",
    "\n",
    "#df_features = df_indexed.pivot(index='prodIndex', columns='custIndex', values='star_rating')\n",
    "\n",
    "df_sparse = df_indexed[0:80000].pivot(index='prodIndex', columns='custIndex', values='star_rating').fillna(0)\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
